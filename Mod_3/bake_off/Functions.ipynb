{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# model tuning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# ensembles\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "# class imbalance\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "# evaluating models\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "# reading in the dataframe\n",
    "raw_data = pd.read_csv('dataset.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(raw_data):\n",
    "    \n",
    "    raw_data['MARRIAGE'].replace(0,3,inplace=True)\n",
    "    raw_data['EDUCATION'].replace([0,5,6],4,inplace=True)\n",
    "    \n",
    "    raw_data.drop('PAY_6',axis = 1,inplace=True)\n",
    "    raw_data['PAY_5'] = np.where(raw_data['PAY_AMT5'] + raw_data['PAY_AMT6'] >= raw_data['BILL_AMT6'],0,1)\n",
    "    raw_data['PAY_4'] = np.where(raw_data['PAY_AMT4'] >= raw_data['BILL_AMT5'],0,raw_data['PAY_5']+1)\n",
    "    raw_data['PAY_3'] = np.where(raw_data['PAY_AMT3'] >= raw_data['BILL_AMT4'],0,raw_data['PAY_4']+1)\n",
    "    raw_data['PAY_2'] = np.where(raw_data['PAY_AMT2'] >= raw_data['BILL_AMT3'],0,raw_data['PAY_3']+1)\n",
    "    raw_data['PAY_0'] = np.where(raw_data['PAY_AMT1'] >= raw_data['BILL_AMT2'],0,raw_data['PAY_2']+1)\n",
    "    \n",
    "    \n",
    "    raw_data['paid_over_6_months'] = raw_data['PAY_AMT1']+raw_data['PAY_AMT2']+raw_data['PAY_AMT3']+raw_data['PAY_AMT4']+raw_data['PAY_AMT5']+raw_data['PAY_AMT6']\n",
    "    \n",
    "    raw_data['spent_6_months'] = (raw_data['BILL_AMT1'] + raw_data['paid_over_6_months']) - raw_data['BILL_AMT6']\n",
    "    return raw_data\n",
    "df = clean_data(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default payment next month</th>\n",
       "      <th>paid_over_6_months</th>\n",
       "      <th>spent_6_months</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>151973</td>\n",
       "      <td>6600</td>\n",
       "      <td>6000</td>\n",
       "      <td>5860</td>\n",
       "      <td>6000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29460</td>\n",
       "      <td>17814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200000</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11424</td>\n",
       "      <td>3353</td>\n",
       "      <td>3</td>\n",
       "      <td>5101</td>\n",
       "      <td>6</td>\n",
       "      <td>6530</td>\n",
       "      <td>8103</td>\n",
       "      <td>1</td>\n",
       "      <td>23096</td>\n",
       "      <td>14609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>19129</td>\n",
       "      <td>4175</td>\n",
       "      <td>41000</td>\n",
       "      <td>51705</td>\n",
       "      <td>700</td>\n",
       "      <td>718</td>\n",
       "      <td>700</td>\n",
       "      <td>0</td>\n",
       "      <td>98998</td>\n",
       "      <td>131143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>780</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>780</td>\n",
       "      <td>1170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "0     200000    2          3         1   30      5      4      3      2   \n",
       "1     200000    2          4         2   27      0      0      0      0   \n",
       "2      20000    2          2         2   28      4      3      2      1   \n",
       "3      50000    1          2         2   23      2      1      0      2   \n",
       "4      20000    1          2         1   47      0      0      0      0   \n",
       "\n",
       "   PAY_5  ...  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  PAY_AMT4  PAY_AMT5  \\\n",
       "0      1  ...     151973      6600      6000      5860      6000      5000   \n",
       "1      0  ...          0         0         0         0         0         0   \n",
       "2      0  ...      11424      3353         3      5101         6      6530   \n",
       "3      1  ...      19129      4175     41000     51705       700       718   \n",
       "4      0  ...          0       780         0         0         0         0   \n",
       "\n",
       "   PAY_AMT6  default payment next month  paid_over_6_months  spent_6_months  \n",
       "0         0                           0               29460           17814  \n",
       "1         0                           0                   0               0  \n",
       "2      8103                           1               23096           14609  \n",
       "3       700                           0               98998          131143  \n",
       "4         0                           0                 780            1170  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling begins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting target and features & splitting for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('default payment next month',axis=1)\n",
    "y = df['default payment next month']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.25,random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base Logistic Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1 score for the base Logistic regressor is: 0.4120370370370371\n"
     ]
    }
   ],
   "source": [
    "# Using \"balanced\" to handle class imbalance\n",
    "logit_base = LogisticRegression(class_weight='balanced',solver='liblinear')\n",
    "\n",
    "logit_base.fit(X_train,y_train)\n",
    "\n",
    "logit_base_preds = logit_base.predict(X_test)\n",
    "\n",
    "print('The f1 score for the base Logistic regressor is:',f1_score(y_test,logit_base_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1 score for the base KNN regressor is: 0.24986420423682784\n"
     ]
    }
   ],
   "source": [
    "knn_base = KNeighborsClassifier()\n",
    "\n",
    "knn_base.fit(X_train,y_train)\n",
    "\n",
    "knn_base_preds = knn_base.predict(X_test)\n",
    "\n",
    "print('The f1 score for the base KNN regressor is:',f1_score(y_test,knn_base_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base Decision tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1 score for the base Decision tree regressor is: 0.24986420423682784\n",
      "The decision tree base precision is: 0.38917089678510997\n",
      "The decision tree base recall is: 0.184\n",
      "The decision tree base accuracy is: 0.7544888888888889\n"
     ]
    }
   ],
   "source": [
    "dt_base = DecisionTreeClassifier()\n",
    "\n",
    "dt_base.fit(X_train,y_train)\n",
    "\n",
    "dt_base_preds = knn_base.predict(X_test)\n",
    "\n",
    "print('The f1 score for the base Decision tree regressor is:',f1_score(y_test,dt_base_preds))\n",
    "print('The decision tree base precision is:',precision_score(y_test,dt_base_preds))\n",
    "print('The decision tree base recall is:',recall_score(y_test,dt_base_preds))\n",
    "print('The decision tree base accuracy is:',accuracy_score(y_test,dt_base_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_log = {\n",
    "                   'tol':[0.0001,.001],\n",
    "                   'C':[1.0,10.], \n",
    "                  'class_weight':['balanced'],\n",
    "                  'random_state':[1,10],\n",
    "                  'solver':['lbfgs', 'liblinear', 'sag', 'saga'], \n",
    "                  'max_iter':[100,200]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='warn',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='warn',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'C': [1.0, 10.0], 'class_weight': ['balanced'],\n",
       "                         'max_iter': [100, 200], 'random_state': [1, 10],\n",
       "                         'solver': ['lbfgs', 'liblinear', 'sag', 'saga'],\n",
       "                         'tol': [0.0001, 0.001]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_logit = GridSearchCV(LogisticRegression(),param_grid_log,cv=5,n_jobs=-1)\n",
    "grid_logit.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_log_pred = grid_logit.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3328467153284671"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test,grid_log_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=1, max_features=4, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=1, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state = 1, n_estimators=100, max_depth=1, max_features=4)\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_preds = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100,200],\n",
    "    'max_depth': [1,2,3,4],\n",
    "    'max_features': [2,3,4,5],\n",
    "    'criterion': ['gini','entropy']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   35.8s\n",
      "[Parallel(n_jobs=-1)]: Done 320 out of 320 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                              class_weight='balanced',\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [1, 2, 3, 4],\n",
       "                         'max_features': [2, 3, 4, 5],\n",
       "                         'n_estimators': [100, 200]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = GridSearchCV(RandomForestClassifier(class_weight='balanced'),param_grid,cv=5,verbose=1,scoring='f1',n_jobs=-1)\n",
    "gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4459124690338563"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, gs.best_estimator_.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44886199942379723"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_.fit(X_train,y_train)\n",
    "f1_score(y_test,gs.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set = pd.read_csv('validation_set.csv',index_col=0)\n",
    "val_set = clean_data(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_preds_val = gs.best_estimator_.predict(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(gs_preds_val).to_csv('gs_rf_preds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.407067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.491320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "count  7500.000000\n",
       "mean      0.407067\n",
       "std       0.491320\n",
       "min       0.000000\n",
       "25%       0.000000\n",
       "50%       0.000000\n",
       "75%       1.000000\n",
       "max       1.000000"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('gs_rf_preds.csv',index_col=0).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 675 candidates, totalling 3375 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   28.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 14.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed: 21.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed: 30.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed: 39.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed: 48.9min\n",
      "[Parallel(n_jobs=-1)]: Done 3375 out of 3375 | elapsed: 51.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constrai...\n",
       "                                     reg_lambda=None, scale_pos_weight=None,\n",
       "                                     subsample=None, tree_method=None,\n",
       "                                     validate_parameters=None, verbosity=None),\n",
       "             iid=False, n_jobs=-1,\n",
       "             param_grid={'colsample_bytree': [0.5, 0.45, 0.4],\n",
       "                         'learning_rate': [0.1, 0.07, 0.05, 0.03, 0.01],\n",
       "                         'max_depth': [3, 4, 5, 6, 7],\n",
       "                         'min_child_weight': [1, 2, 3],\n",
       "                         'n_estimators': [100, 300, 500]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_xgb = xgb.XGBClassifier(objective = 'binary:logistic')\n",
    "param_dist = {'n_estimators': [100,300,500],\n",
    "              'learning_rate': [0.1,0.07,0.05,0.03,0.01],\n",
    "              'max_depth': [3, 4, 5, 6, 7],\n",
    "              'colsample_bytree': [0.5,0.45,0.4],\n",
    "              'min_child_weight': [1, 2, 3]\n",
    "             }\n",
    "gsearch1 = GridSearchCV(\n",
    "    estimator = clf_xgb,\n",
    "    param_grid = param_dist, \n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    iid=False, \n",
    "    cv=5)\n",
    "gsearch1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31756756756756754"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test,gsearch1.best_estimator_.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
